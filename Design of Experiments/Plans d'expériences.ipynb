{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TP Plans d'expériences\n",
        "> LAMNAOIR Imane  \n",
        "> SROUR Mathieu  \n",
        "> ALLOUCH Omar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvnH-R5Y6mvK"
      },
      "source": [
        "## Exercice 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__45wd_IsSgm"
      },
      "source": [
        "Nous disposons de 4 variables:\n",
        "\n",
        "A= L'amplitude du pic de débit $q_{\\max }$\n",
        "\n",
        "$\\mathrm{B}=$ Le temps de montée du débit $t_m$\n",
        "\n",
        "$\\mathrm{C}=$ La durée totale de la crue $d$\n",
        "\n",
        "$\\mathrm{D}=$ La proportion de la digue rompue $p$.\n",
        "\n",
        "Normalement, un plan factoriel complet nécessiterait $2^4=16$ expériences pour explorer toutes les combinaisons possibles des niveaux des quatre facteurs. Cependant, en raison de contraintes budgétaires, nous voulons réduire le nombre d'expériences à 8 expériences soit la moitié pour des raisons de coût.\n",
        "\n",
        "Pour cette raison, on construit un plan factoriel fractionnaire en commençant d'abord par la réalisation d'un plan complet avec $(p-q)=3$ facteurs $\\mathrm{A}$, $\\mathrm{B}$ et $\\mathrm{C}$ puis on définit le facteur qui reste par un produit entre les 3 premiers facteurs. Puisque l'interaction $\\mathrm{ABC}$ est certainement négligeable et du coup on confond la facteur $\\mathrm{D}$ avec l'interaction $D=A * B * C$.\n",
        "\n",
        "La matrice du plan est égale donc à avec la première colonne de 1:\n",
        "$$\n",
        "X=\\left[\\begin{array}{ccccc}\n",
        "1 & 1 & 1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 & -1 & -1 \\\\\n",
        "1 & 1 & -1 & 1 & -1 \\\\\n",
        "1 & 1 & -1 & -1 & 1 \\\\\n",
        "1 & -1 & 1 & 1 & -1 \\\\\n",
        "1 & -1 & 1 & -1 & 1 \\\\\n",
        "1 & -1 & -1 & 1 & 1 \\\\\n",
        "1 & -1 & -1 & -1 & -1\n",
        "\\end{array}\\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45Ay7xPW1mow"
      },
      "source": [
        "### Question 2 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wnWruKo11we",
        "outputId": "b84cd41e-76b8-4d46-dcbc-9f5b7f126f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X:\n",
            "[[ 1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1. -1. -1.]\n",
            " [ 1.  1. -1.  1. -1.]\n",
            " [ 1.  1. -1. -1.  1.]\n",
            " [ 1. -1.  1.  1. -1.]\n",
            " [ 1. -1.  1. -1.  1.]\n",
            " [ 1. -1. -1.  1.  1.]\n",
            " [ 1. -1. -1. -1. -1.]]\n",
            "(X'X):\n",
            "[[8. 0. 0. 0. 0.]\n",
            " [0. 8. 0. 0. 0.]\n",
            " [0. 0. 8. 0. 0.]\n",
            " [0. 0. 0. 8. 0.]\n",
            " [0. 0. 0. 0. 8.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "p = 4\n",
        "X = np.ones((8, p + 1))\n",
        "\n",
        "A = np.array([1, 1, 1, 1, -1, -1, -1, -1])\n",
        "B = np.array([1, 1, -1, -1, 1, 1, -1, -1])\n",
        "C = np.array([1, -1, 1, -1, 1, -1, 1, -1])\n",
        "D = A * B * C\n",
        "\n",
        "X[:, 1:] = np.column_stack((A, B, C, D))\n",
        "\n",
        "XTX = X.T @ X\n",
        "\n",
        "print(\"X:\")\n",
        "print(X)\n",
        "\n",
        "print(\"(X'X):\")\n",
        "print(XTX)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bv2mnjj2Url"
      },
      "source": [
        "Le plan est bien orthogonal par ce que $\\left(X^T X\\right)^{-1}$ est proportionnel à l'identité par un facteur de 8\n",
        "La clé d'un plan est l'ensemble des relations que l'on exprime sous la forme $1=\\ldots$ Dans notre cas la clé est égale à $A * B * C * D=1$. La résolution correspond au nombre inférieur de symboles des éléments de l'alias 1, dans notre cas, on a une résolution de IV. Autrement dit, un effet principal ne peut être confondu avec une interaction \"double\", mais certaines interactions \"doubles\" sont confondues entre elles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFTbmrKl2pgT"
      },
      "source": [
        "### Question 3 :\n",
        "\n",
        "Si on prend en considération tous les interactions, on aura $2^4=16$ paramètres à estimer.\n",
        "\n",
        "Cepandant, si on néglige les interactions de facteurs supérieures ou égales à 3 facteurs on aura $2^4-\\left(\\begin{array}{l}4 \\\\ 3\\end{array}\\right)-\\left(\\begin{array}{l}4 \\\\ 4\\end{array}\\right)=11$ paramètres à estimer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPyXVDuJ3ipN"
      },
      "source": [
        "### Question 4 :\n",
        "L'équation du modèle est la suivante :\n",
        "$$\n",
        "Y=\\alpha_0+\\alpha_A * A+\\alpha_B * B+\\alpha_C * C+\\alpha_D * D+\\alpha_{A C} * A C+\\alpha_{A B} * A B+\\alpha_{B C} * B C+\\epsilon\n",
        "$$\n",
        "\n",
        "En se basant sur la clé du plan, $A B C D$ représente le générateur d'alias. Du coup on multiplie chacun des effets principale et les interaction avec $A B C D$ afin d'obtenir les alias qui vont nous servir pour calculer les 11 pramètres et on trouve les relations suivantes: $A=B C D \\quad B=A C D \\quad C=A B D \\quad A B=C D \\quad A C=B D \\quad B C=A D$\n",
        "\n",
        "Sauf que dans notre cas on va suffir juste des interaction de facteurs inférieur strictement à 3 facteurs, et du coup on trouve les relations suivantes:\n",
        "$$\n",
        "\\begin{gathered}\n",
        "\\alpha_0=\\beta_0 \\\\\n",
        "\\alpha_A=\\beta_A \\\\\n",
        "\\alpha_B=\\beta_B \\\\\n",
        "\\alpha_C=\\beta_C \\\\\n",
        "\\alpha_D=\\beta_D \\\\\n",
        "\\alpha_{A C}=\\beta_{A C}+\\beta_{B D} \\\\\n",
        "\\alpha_{B C}=\\beta_{B C}+\\beta_{A D} \\\\\n",
        "\\alpha_{A C}=\\beta_{A C}+\\beta_{B D}\n",
        "\\end{gathered}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmuD29PV4KL-"
      },
      "source": [
        "### Question 5 :\n",
        "Nous débutons en extrayant les valeurs de la réponse \\(Y\\) pour 8 simulations. Ensuite, nous calculons les estimations pour les 8 contrastes en utilisant le code suivant et les relations vues en cours:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqY71RvA5VqK",
        "outputId": "4fe2bae6-04a4-4b4a-be42-a10b829ae752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Estimate\n",
            "intercept  23.081329\n",
            "A          33.672746\n",
            "B          -1.685730\n",
            "C          26.109105\n",
            "D           6.339074\n",
            "AC         43.939126\n",
            "BC          5.450260\n",
            "AB         -0.499928\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def fonction_test(X):\n",
        "    X = -1 + 6 * (X + 1) / 2\n",
        "    X[0] = 5 * X[0]\n",
        "    X[1] = -(X[1] / 5 - 1)\n",
        "\n",
        "    y1 = X[2] * np.exp(-(10 * X[1]) ** 2 / (60 * X[2] ** 2 + 1))\n",
        "    y2 = (X[1] + X[3]) * np.exp(X[2] / 500)\n",
        "    y3 = (X[2] * (X[0] - 2)) * np.exp(-(X[3]) ** 2 / (100 * X[2] ** 2))\n",
        "\n",
        "    return y1 + y2 + y3 + X[0] * (X[3] / 10)\n",
        "\n",
        "N = 8\n",
        "\n",
        "Y = np.zeros(N)\n",
        "\n",
        "for i in range(N):\n",
        "    Y[i] = fonction_test(X[i, 1:5])  # Index 1:5 pour correspondre à X[i, 2:5] en R\n",
        "\n",
        "X_t = np.column_stack([X, X[:, 1] * X[:, 3], X[:, 2] * X[:, 3], X[:, 1] * X[:, 2]])\n",
        "\n",
        "alpha = (1/8) * X_t.T @ Y\n",
        "\n",
        "contrast_names = [\"intercept\", \"A\", \"B\", \"C\", \"D\", \"AC\", \"BC\", \"AB\"]\n",
        "alpha_df = pd.DataFrame(alpha, index=contrast_names, columns=[\"Estimate\"])\n",
        "print(alpha_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercice 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "from scipy.stats.qmc import Halton, Sobol, scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define the density function $f_{X}(x)$, and the function $f(x)$, and a function to test if a point is in the region $A$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    if x <= -1:\n",
        "        return 0\n",
        "    elif -1 < x <= 0:\n",
        "        return x + 1\n",
        "    elif 0 < x <= 1:\n",
        "        return -x + 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def f_x(x):\n",
        "    return f(x[0]) * f(x[1]) * f(x[2]) * 8  # 8 is the scaling factor to obtain a valid pdf\n",
        "\n",
        "\n",
        "def A(x):\n",
        "    return x[0] > 0 and x[1] > 0.9 and x[2] < -0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As per the comment above, we multiply the density value of a point x by _8_ to account for the volume of the cube in $\\mathbb{R}^{3}$, if we don't do that the integration of the density function over the domain gives _0.125_ instead of _1_, which means it's no longer a _pdf_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**We define 2 functions:**\n",
        "- `quasi_monte_carlo` generates `n` points following a low discrepancy `sequence`\n",
        "- `repeated_quasi_monte_carlo` repeats the `quasi_monte_carlo` function and returns the mean of the result to reduce the impact of random variability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def quasi_monte_carlo(n, sequence):\n",
        "    l_bounds = [-1, -1, -1]\n",
        "    u_bounds = [1, 1, 1]\n",
        "    X = sequence(3, scramble=True).random(n)\n",
        "    X = scale(X, l_bounds, u_bounds)\n",
        "    A_points = X[np.apply_along_axis(A, 1, X)]\n",
        "    Y = np.apply_along_axis(f_x, 1, A_points)\n",
        "    return np.sum(Y) / n\n",
        "\n",
        "\n",
        "def repeated_quasi_monte_carlo(n, sequence, m):\n",
        "    return np.mean([quasi_monte_carlo(n, sequence) for _ in range(m)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run the functions and see the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##################### Single run #####################\n",
            "Proportion of points in A for Sobol:   0.000447103139955776\n",
            "Done in: 0.07205495900052483s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points in A for Halton:  0.00044816805242572016\n",
            "Done in: 0.11663967200001935s\n",
            "######################################################\n",
            "\n",
            "##################### Repeated run #####################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/omar/miniconda3/lib/python3.11/site-packages/scipy/stats/_qmc.py:804: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
            "  sample = self._random(n, workers=workers)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of points in A for Sobol:   0.000451845633658298\n",
            "Done in: 0.6113522830019065s\n",
            "Proportion of points in A for Halton:  0.0004525976140567989\n",
            "Done in: 1.1047922739999194s\n",
            "########################################################\n"
          ]
        }
      ],
      "source": [
        "n = 50000\n",
        "\n",
        "print(\"##################### Single run #####################\")\n",
        "start_time = timeit.default_timer()\n",
        "print(\"Proportion of points in A for Sobol:  \", quasi_monte_carlo(n, Sobol))\n",
        "print(f\"Done in: {timeit.default_timer() - start_time}s\")\n",
        "start_time = timeit.default_timer()\n",
        "print(\"Proportion of points in A for Halton: \", quasi_monte_carlo(n, Halton))\n",
        "print(f\"Done in: {timeit.default_timer() - start_time}s\")\n",
        "print(\"######################################################\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"##################### Repeated run #####################\")\n",
        "m = 10\n",
        "start_time = timeit.default_timer()\n",
        "print(\"Proportion of points in A for Sobol:  \", repeated_quasi_monte_carlo(n, Sobol, m))\n",
        "print(f\"Done in: {timeit.default_timer() - start_time}s\")\n",
        "start_time = timeit.default_timer()\n",
        "print(\"Proportion of points in A for Halton: \", repeated_quasi_monte_carlo(n, Halton, m))\n",
        "print(f\"Done in: {timeit.default_timer() - start_time}s\")\n",
        "print(\"########################################################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Comparison with the analytical value**\n",
        "\n",
        "\n",
        "$\\mathbb{P}(X \\in A) = \\int_{0}^{1} \\int_{0.9}^{1} \\int_{-1}^{-0.4} (x_1 + 1) \\cdot (x_2 + 1) \\cdot (-x_3 + 1) \\, dx_1 \\, dx_2 \\, dx_3 = 4.5 \\times 10^{-4}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion\n",
        "\n",
        "The solve the problem we wrote the probability as an integral, then estimated the integral using quasi-Monte Carlo (Monte Carlo using low discrepancy sequences)  \n",
        "Since the problem is not too hard to solve analytically, we did the calculations and compared the analytical solution to that of the code, and to no surprise the results were in agreement.\n",
        "\n",
        "Result-wise there are almost no differences, but performance-wise it seems the `Sobol` sequence is slightly faster, and this difference in execution time accumulated quickly to the point where `Halton` almost took twice the time `Sobol` takes for only 10 runs.\n",
        "\n",
        "In conclusion, the use of low discrepancy sequences, such as Sobol and Halton sequences, provides a powerful and efficient approach for solving numerical problems, particularly in the context of Monte Carlo simulations and quasi-Monte Carlo integration. These sequences exhibit improved coverage of the sample space compared to traditional random sequences, leading to a more uniform exploration of the domain.\n",
        "\n",
        "The advantages of low discrepancy sequences include their ability to reduce variance and accelerate convergence rates, especially in higher dimensions. By systematically distributing points across the space, these sequences help achieve a more accurate and stable estimation of integrals, probabilities, and other numerical quantities.\n",
        "\n",
        "Moreover, the deterministic nature of low discrepancy sequences ensures reproducibility, a crucial aspect in scientific computing and experimentation. This feature allows for consistent and comparable results across multiple runs, facilitating the analysis of algorithmic performance.\n",
        "\n",
        "Despite their advantages, it is important to note that the effectiveness of low discrepancy sequences may depend on the specific characteristics of the problem at hand. In certain scenarios, the choice of a particular low discrepancy sequence and the understanding of its properties can significantly impact the success of the numerical solution."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
